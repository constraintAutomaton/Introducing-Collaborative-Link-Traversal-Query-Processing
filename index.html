<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
  <meta charset="utf-8" />
  <title property="foaf:name schema:name">Introducing Collaborative Link Traversal Query Processing in the context of structured decentralized environment</title>
  <link rel="stylesheet" media="screen" href="styles/screen.css" />
  <link rel="stylesheet" media="print"  href="styles/print.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  
  <meta name="citation_title" content="Introducing Collaborative Link Traversal Query Processing in the context of structured decentralized environment">
  <meta name="citation_author" content="Bryan-Elliott Tam" />
  
  <meta name="citation_publication_date" content="2023/05/20" />
</head>

<body prefix="dctypes: http://purl.org/dc/dcmitype/ pimspace: http://www.w3.org/ns/pim/space# rsa: http://www.w3.org/ns/auth/rsa# cert: http://www.w3.org/ns/auth/cert# wgs: http://www.w3.org/2003/01/geo/wgs84_pos# biblio: http://purl.org/net/biblio# bibo: http://purl.org/ontology/bibo/ book: http://purl.org/NET/book/vocab# ov: http://open.vocab.org/terms/ doap: http://usefulinc.com/ns/doap# dbr: http://dbpedia.org/resource/ dbp: http://dbpedia.org/property/ sio: http://semanticscience.org/resource/ opmw: http://www.opmw.org/ontology/ deo: http://purl.org/spar/deo/ doco: http://purl.org/spar/doco/ cito: http://purl.org/spar/cito/ fabio: http://purl.org/spar/fabio/ solid: http://www.w3.org/ns/solid/terms# acl: http://www.w3.org/ns/auth/acl# dio: https://w3id.org/dio# lsc: http://linkedscience.org/lsc/ns#" typeof="schema:CreativeWork sioc:Post prov:Entity lsc:Research">
  <header>
  <h1 id="introducing-collaborative-link-traversal-query-processing-in-the-context-of-structured-decentralized-environment">Introducing Collaborative Link Traversal Query Processing in the context of structured decentralized environment</h1>

  <ul id="authors">
    <li><a rev="lsc:participatesIn" property="foaf:maker schema:creator schema:author schema:publisher" href="https://github.com/constraintAutomaton" typeof="foaf:Person schema:Person" resource="">Bryan-Elliott Tam</a></li>
  </ul>

  <ul id="affiliations">
    <li id="myaffiliation">IDLab, Department of Electronics and Information Systems, Ghent University – imec</li>
  </ul>

  <section id="abstract" inlist="" rel="schema:hasPart" resource="#abstract">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Abstract</h2>
      <!-- Context -->
      <p>Decentralized web environments aim to give users data autonomy and control.
<!-- Need -->
Data sovereignty focuses on privacy and provider choice,
but the concept is not complete if it does not include the concrete usage of the data,
if when it comes to the working of applications sovereignty can be
surrendered to the owner of the computational units or apps.
<!-- Task -->
The exploration and retrieval of information is a core functionality of web-based social
applications because it is from this that shared experiences to foster interactions are created.
A promising example of web discovery techniques is Link Traversal Query Processing (LTQP),
a SPARQL query paradigm that aims at exploring the web to answer queries by following the links provided by the documents,
hence exploiting the connectivity of data sources.
<!-- Object -->
In my doctoral research, I introduce Collaborative Link Data Query Processing,
a paradigm where multiple query engines collaborate to improve query completeness and execution time in LTQP.
<!-- Findings -->
I divided the research on the cooperation of query engines into two parts:
1) Improving the completeness of results, by exploring more of the search space,
and 2) reducing the potentially long query execution time by caching results.
<!-- Conclusion -->
To validate this proposal, I will develop a prototype and evaluate it using existing benchmarks.
<!-- Perspectives -->
Based on my analysis of the state of the art,
previous studies have made contributions to collaborative SPARQL query and RDF peer-to-peer caching.
However, there is currently a research gap regarding the investigation of such systems in
the context of LTQP and LTQP within a structured decentralized environment.</p>

    </div>
</section>

</header>

<main>
  <!-- Add sections by specifying their file name, excluding the '.md' suffix. -->
  <section id="introduction" inlist="" rel="schema:hasPart" resource="#introduction">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Introduction</h2>

      <p>Decentralized web initiatives give users more control over their data.
It can be formalized in a concept called data sovereignty. <span class="references">[<a href="#ref-1">1</a>]</span> defined this concept as 
<q>the power an individual has over their data.</q><span class="references">[<a href="#ref-1">1</a>]</span>.
It can also be interpreted as <q>the self-determination of 
individuals and organizations concerning to the use of their data</q><span class="references">[<a href="#ref-1">1</a>]</span>.
This means that individual and legal entities
<q>can choose where [their] data is stored and who is granted access to it.</q><span class="references">[<a href="#ref-1">1</a>]</span>
In this PhD program, I attempt to move the definition of power and control,
in the context of decentralized web environments, from a more consumer choice 
<span class="references">[<a href="#ref-2">2</a>, <a href="#ref-3">3</a>, <a href="#ref-4">4</a>]</span>,
the right to choose who will use my data,
to a definition that includes the right of the users as a collective to make use of their data without relying on
a third-party distributor with substantial computational power.
In the context of data usage, sovereignty, and control are vested in the owner of the computational unit.
This ownership empowers them to make decisions that may diverge from the desires or interests of the users <span class="references">[<a href="#ref-4">4</a>]</span>.
Additionally, it facilitates the utilization of users as products to be sold or as an unpaid source of revenue,
even when the data is anonymized <span class="references">[<a href="#ref-2">2</a>, <a href="#ref-4">4</a>]</span>.
To improve this sovereignty, my emphasis is on querying because, in the case of social applications, the request for information, 
its discovery process,  particularly when considering complex concepts like serendipity <span class="references">[<a href="#ref-5">5</a>]</span>
and its propagation are the core functionalities performed by those applications.
Concretely, I propose Collaborative Link Traversal Query Processing (CLTQP),
a Link Traversal Query Processing (LTQP) paradigm where every user can share
their computational power when querying. 
This collaboration increases query result completeness 
and reduces execution time for all users,
in essence creating a unified and powerful engine. 
With this collective participation, 
it would be possible at little cost to provide a more democratic economic base from which
users could have more power to choose features for social applications that cater to their
desire and interest and start social applications with a lesser monetary barrier.
This paper is divided as follows, first,
<a href="#litterature_review">related work</a> is presented,
after the <a href="#proposal">research proposal</a> is made,
then the <a href="#evaluation">methodology</a> is explained and there is a short <a href="#conclusion">conclusion</a>.</p>

      <!-- 
* Problem statement
    * what is the problem that you are trying to solve? Importance: Why is this problem important and for whom? Who will benefit and who should care? What is the impact of solving this problem (for the research community, or society in general).
* Related work 
    * Has a solution to this problem been attempted before and how? If not, have research efforts tried or solved similar problems? What can you learn from these efforts? If you are addressing an existing problem, what are the limitations of current solutions? What are you adding that is novel? Why?
* Research question(s) and hypotheses 
    * What hypotheses do you make in formulating your solution? What are the questions you need to answer in order to solve the problem? Are there boundary cases you plan to exclude or assumptions you base on?
* Preliminary results 
    * What research methods did you follow in your proposal? Have you produced any results so far?
* Evaluation
    * How do you know you’ve answered your question(s)? What are the methods you apply to test your hypotheses? Have you identified criteria to measure the degree of success of your solution?
* Reflection and future work: Are there any limitations in your approach? What are your planned next steps to complete your investigation?

-->
    </div>
</section>
 <!-- 2 -->
  <section id="litterature_review" inlist="" rel="schema:hasPart" resource="#litterature_review">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Related Work</h2>

      <h3 id="litterature_review_LTQP">Link Traversal Query Processing</h3>

      <p>LTQP is a technique that consists of recursively looking up URLs from dereferenced URIs acquired by the query engine
to explore the surrounding information around the original response <span class="references">[<a href="#ref-6">6</a>]</span> using the follow-your-nose
principle of Linked Data, compared to traditional SPARQL queries that only query one document,
and Federated Query Processing where the data sources are known beforehand.
The query first starts with a small set of URIs called seed URIs <span class="references">[<a href="#ref-6">6</a>]</span> that form
the initial data sources for the execution.
The engine then resolves the URIs encounters to explore unknown data sources,
following a lookup policy.
Link traversal has great exploratory potential.
In its traditional form, it consists in following, more or less naively,
the links inside the response payload and dereferencing them to get new data sources. 
However, Link Traversal comes with some difficulties,
such as the open-endedness of the web and query planning <span class="references">[<a href="#ref-7">7</a>]</span>. 
Reachability criteria can be defined to restrict the links that are followed based on conditions.
Classical examples are <code>cAll</code>, which follows every link, and <code>cMatch</code>, which follows links that match the query pattern <span class="references">[<a href="#ref-8">8</a>]</span>.</p>

      <h3 id="collaborative-sparql-querying">Collaborative SPARQL Querying</h3>

      <p>Collaborative SPARQL Querying in that context consists of using multiple agents to facilitate querying by
diminishing the computation load of the execution or the discovery of data sources <span class="references">[<a href="#ref-9">9</a>]</span>. 
<a property="schema:citation http://purl.org/spar/cito/cites" href="https://hal-nantes-universite.archives-ouvertes.fr/hal-01805154">Snob</a> <span class="references">[<a href="#ref-10">10</a>]</span> proposes a mechanism for collaborative query based
on the continuous execution of queries over rotating browser data sources. 
The browsers form an unstructured peer-to-peer (P2P) network where each peer has
a random and a profile-based (browsers with similar profiles execute similar queries) partial view of the network.
The browsers can share their intermediary results and at specific intervals,
the peers are randomly shuffled by asking the peers that a browser knows for other peers.
With this technique,
it becomes possible to enhance the completeness of query results over time without the need to query every individual data source.
<a property="schema:citation http://purl.org/spar/cito/cites" href="https://doi.bak.org/10.1145/3442381.3450037">ColChain</a> <span class="references">[<a href="#ref-11">11</a>]</span> has a different approach. 
The query engines still have a partial view of the network but it is based on communities instead of being random or profile-based.
A community, in the ColChain context, is a set of
<q>nodes that participate in and observe [each other] and the fragments published [between them]</q> <span class="references">[<a href="#ref-11">11</a>]</span>.
So the division of the network is made intentionally by the users.
When querying the SPARQL query engine, it will look at its own data sources, then the data sources of the communities it knows.
To discover new communities, the engine inquires peers to identify unknown communities.
The collaborative aspect lies in the partition of a “global” knowledge graph into intentional semantic units and in the
maintenance and particularly update of the collective data sources, which is an important contribution of ColChain but is not related to the aim of my research.
Other academic contributions have also aimed to leverage the social links between data sources to diminish the query execution time by not flooding the network when querying, such as in
<span class="references">[<a href="#ref-12">12</a>]</span>.
Also in that realm of studies, contributions have focused on using the structure of the object that is modeled,
such as academic papers, instead of the social links between the data sources,
as in the contribution of <span class="references">[<a href="#ref-13">13</a>]</span>.</p>

      <h3 id="litterature_review_P2P_caching">P2P caching in the context of the web</h3>

      <p>We define P2P caching as a particular case of collaborative querying where the query engine share with each other in a network of peers,
their already computed and valid results.
Squirrel <span class="references">[<a href="#ref-14">14</a>]</span> proposed a P2P caching mechanism,
where the URLs are mapped to keys inside a distributed hash table (DHT).
If the user does not have in its local cache the content desired,
it first makes a query to the P2P network before requesting the URL in question.
Squirrel does not propose a mechanism to take into consideration the locality of the client and the node’s acting.
Flower-CDN <span class="references">[<a href="#ref-15">15</a>]</span> proposes to modify the keys of the DHT to consider the locality.
The content of the websites is distributed to peers of a locality,
inside this locality a super-peer knows where to locate every content of all the websites of the locality.
When a client makes a query to the DHT,
the DHT directs to the super peer closest to the locality of the client and 
the super peer finds the content requested by the client.
Behave <span class="references">[<a href="#ref-16">16</a>]</span> proposed another paradigm instead of using a structured network with a potentially slow DHT,
it relies on an unstructured network where each peer has a partial view of the whole web.
Each peer’s view of the network is partially random and partially based on the websites visited to create a 
<q>behavioral locality</q> <span class="references">[<a href="#ref-16">16</a>]</span>.
It uses a gossip protocol, at certain times the peers exchange randomly the nodes they know to change their view on the network.
CyCLaDEs <span class="references">[<a href="#ref-17">17</a>]</span> adapted the concept of Behave for the use case of SPARQL query of RDF documents.</p>

    </div>
</section>
 <!-- 2 -->
  <section id="problem_statement" inlist="" rel="schema:hasPart" resource="#problem_statement">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Problem statement</h2>

      <h3 id="proposal">Proposal</h3>

      <p>This paper aims to create a SPARQL query paradigm called CLQTP.
It consists of using multiple SPARQL query engines with the aim of improving the completeness
of queries by exploring more of the search space and reducing the query execution time through the means of exchange of results.
Both problems have been engaged in the academic literature, but not in the case of LTQP from my knowledge and considering the distributed SPARQL querying domain <span class="references">[<a href="#ref-18">18</a>]</span>.
In this PhD project, I will apply this query paradigm in the context of Solid, 
which implies that there is a strong consideration for privacy during querying <span class="references">[<a href="#ref-19">19</a>]</span>
and a structured environment that can be leveraged to speed up the query <span class="references">[<a href="#ref-20">20</a>]</span>.
The first problem I try to solve is to increase the query completeness.
To do so, CLTQP attempts to explore more of the search space by having multiple query engines engaging in 
non-overlapping partitions of the huge or pseudo-infinite search domain and executing the query.
Hence, in the same amount of time, having more triple processes compared to an approach with one engine.
An important property emerging from the traversal of links is a structural proximity bias of the query results, which
means that from the link traversal method, some data sources tend to be discovered more easily regardless of their potential
influence on the query completeness and the interpretation of the query results.
The bias has two interconnected sources: a sensitivity to the initial conditions induced by the seed URLs and the structure of the web,
which is not a fully connected graph.
Hence, a data source that takes more steps to be accessed, in regards to the seed URLs will be more difficult to discover.
Corollary, there is a bias based on the popularity of the data source, as it is easier to find a data source that is
referenced more times and in a wide range of data source types (by data source types, I mean data sources that focus on specific topics)
than data sources having the reverse properties.
Hence by exploring more of the search space, there is more chance to discover those data sources.
The second problem is to reduce the execution time, and we explore the mean of P2P caching to alleviate this issue.
<span class="references">[<a href="#ref-21">21</a>]</span> demonstrates that caching in LTQP can help improve the completeness of results,
but in some conditions, the query execution time can be increased.
In the <a href="#literature_review_P2P_caching">literature</a>, there are contributions on the topic of P2P caching,
but from my knowledge, none engage with the problem of LTQP and its particularities,
such as long execution time, exploration of multiple sources, and difficulty in attaining completeness,
which may change the conclusion of the caching and network strategy.
Additionally, in environments like Solid, privacy is an additional consideration for caching <span class="references">[<a href="#ref-22">22</a>]</span>.
It has to be considered that a mechanism to incentivize reciprocity is necessary to ensure fairness and the good functioning of the system.
It can be implemented in multiple ways, for example, as an obligation to participate in a ratio of queries,
a number of triples or links to provide, and so on.
Their enforcement could be managed by a community-style structure with policies in that regard.
Given a user doesn’t respect the policy, then they cannot access the results of that community,
so it is a form of social contract.</p>

      <h3 id="research_question">Research questions and Hypotheses</h3>

      <p>Building on the proposal and the related works of <a href="#litterature_review">Section 2</a> 
research questions and hypotheses are formalized to guide the study.</p>
      <ul>
<li><span class="question_hypothesis">Question 1</span>: Can we achieve better query result completeness (and access isolated data sources) 
and better query execution time in the context of LTQP by making multiple SPARQL query engines collaborate?</li>

<li><span class="question_hypothesis">Question 2</span>: How can we minimize the overlapping of data sources exploration during CLTQP to avoid useless repeated query processing?</li>

<li><span class="question_hypothesis">Question 3</span>: How can we reduce query execution time by utilizing P2P caching in the context of CLTQP?</li>

<li><span class="question_hypothesis">Hypothesis 1</span>: It is possible to partition the search space in the context of CLTQP,
in a way that the query processing time of overlapping data sources is less than the time to process distinct data sources.
</li>

<li><span class="question_hypothesis">Hypothesis 2</span>: We can exploit the structural aspect of Solid to obtain a ratio of query execution time
similar to their consideration in LTQP.
</li>

<li><span class="question_hypothesis">Hypothesis 3</span>: Given a large enough search space,
as in the number of data sources is such as the execution time is not dominated by the communication time,
then there is a reverse relation between the number of engines collaborating and 
the execution time and a direct relation with the number of data sources explored. 
</li>
</ul>

      <p>Question 1 is the main question of my work, which aims at determining if CLTQP is a useful query paradigm.
Questions 2 and 3, on the other hand, are asked to determine the efficiency of the specific method 
that will be employed to solve the two main problems.
Those questions can be extended to consider the number
of query engines and the types of scenarios (query, data sources, privacy policy, and so on) encountered.
The hypotheses are the intuitive expected results and set a ground base for the development of my approaches.</p>

    </div>
</section>
 <!-- 2 -->
  <section id="methodology" inlist="" rel="schema:hasPart" resource="#methodology">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Methodology</h2>

      <p>As discussed in <a href="#proposal">the proposal</a>, my work can be divided into two sub-problems;
the division of the search space and the caching. 
This implies two sets of potential solutions detailed below.</p>

      <h3 id="search-domain-division-problem">Search domain division problem</h3>

      <p>The first problem I try to solve is to increase the query completeness;
For that purpose we try to divide the search space among peers.
It has to be considered first that we don’t know in advance the topology of the domain,
so we cannot divide the search space a priori.</p>

      <ul>
        <li>
          <p><span class="question_hypothesis">Collect the seed URLs and divide them between the query engines</span>: 
The advantage of this strategy is the communication between the engines is minimal,
at the start or at a moment when we have a large number of URLs we let the engines execute the query on their own and at
the stopping condition, the engine share their results.
The limitation of this strategy is that we don’t consider if the data sources discoverable inside the seed URLs overlaps.</p>
        </li>
        <li>
          <p><span class="question_hypothesis">Set the reachability criteria of each engine so that they cannot or are less likely to have overlapping search field</span>:
The advantage of this strategy is, like the first one, the communication between engines is low.
However, unlike the previous one, there is a mechanism to avoid redundant calculations.
By doing so, the query engines have a lookup policy that restricts links visited by others.
For example, the engines might be responsible for a specific semantic section of the domain, 
e.g.: cities in geospatial query. 
The limitation of this strategy is that the criteria might have to be changed depending on the executed query
and the type of dataset from which we expect to find results.</p>
        </li>
        <li>
          <p><span class="question_hypothesis">Use a global link queue shared between all the query engines</span>:
The advantage of this strategy is that it’s a simple way to avoid redundant calculations as all engines have the same link queue.
Every engine can then execute the query on their own with no consideration for redundancy.
Another possibility would be to let one peer do the join operation while the other peers handle the traversal and
the execution of the query as inspired by the “slave-master” paradigm of <span class="references">[<a href="#ref-18">18</a>]</span>.
The problem with this strategy is the necessary communication and the potential locking mechanism to avoid inconsistencies.</p>
        </li>
      </ul>

      <p>I am planning to build a prototype using the SPARQL meta query engine <a property="schema:citation http://purl.org/spar/cito/cites" href="https://comunica.github.io/Article-ISWC2018-Resource/">Comunica</a> <span class="references">[<a href="#ref-23">23</a>]</span>,
because it already has LTQP algorithms implemented and it is a highly extensible software which 
will facilitate the implementation of those algorithms.
I will evaluate it against the Solid social media benchmark;
<a href="https://github.com/SolidBench/SolidBench.js">SolidBench</a> <span class="references">[<a href="#ref-20">20</a>]</span>
and compare the results with other LTQP approaches.
I will evaluate those methods while varying the number of engines 
collaborating by increasing the number until the performance stagnates or diminish.
I propose to measure the following metrics:</p>

      <ul>
        <li>Result accuracy: The F-score; a fraction indicating the correctness and completeness of results</li>
        <li>Query execution time: The total time it takes to complete a query</li>
        <li>The ratio between the execution time and the communication time between the engines
<!-- Not sure yet how to do it--></li>
        <li>Ability to access isolated documents: Measured by analyzing the number of links leading to query-relevant data sources and evaluating their actual contribution</li>
        <li>Overlapping of the search space exploration of the Query engine: The number of times a triple and data source has been queried</li>
        <li>Query result arrival times: The time it takes for each triple from the beginning of the query to be obtained</li>
      </ul>

      <h3 id="caching-problem">Caching problem</h3>

      <p>The second problem is to reduce the query execution time by using already computed results from a shared cache.
The information cached could be the <em>data source URLs that are contributing to a query</em>,
the <em>joint</em>, given some triple patterns to avoid their calculations or the <em>triple patterns</em>.
The cache could also be interpreted as a checkpoint for a longer execution or as a map of the data sources to explore.
I propose to investigate those two strategies:</p>

      <ul>
        <li>
          <p><span class="question_hypothesis">
Use an unstructured network where the peers are clustered based on their behavior</span>: 
The advantage of this strategy is that the lookup time to find information in the cache is constant and the peers know 
have a high probability of possessing the knowledge desired. 
The clustering can be based on the engines that has engaged in a query collaboration with the subject engine.
The disadvantage of that method is that it relies on a type of self-organization of the network of engines,
it does not consider that engines that have not collaborated might still have results in common.</p>
        </li>
        <li>
          <p><span class="question_hypothesis">Use a DHT to find the cached element</span>:
The advantage of this approach is that we can get every cached element of the engines implementing the protocol.
The disadvantage is that the lookup time is logarithmic with the number of elements cached,
also the private information of the users will be dispersed in the DHT, with no regard to the will of the user <span class="references">[<a href="#ref-9">9</a>]</span>,
but there are strategies with the combination of a gossip protocol to keep privacy <span class="references">[<a href="#ref-22">22</a>]</span>.
Also, an alternative would be to not share private information.</p>
        </li>
      </ul>

      <p>Building on the evaluation method of the first set of solutions, those metrics are added:
The Access time: The time it takes to retrieve information from the cache and the Cache miss and cache hit rates</p>
    </div>
</section>
 <!-- 1 -->
  <section id="conclusion" inlist="" rel="schema:hasPart" resource="#conclusion">
<div datatype="rdf:HTML" property="schema:description">
      <h2 property="schema:name">Conclusion</h2>

      <p>In this paper, I present my proposal for my PhD research and the state of the art associated with it.
My project aims at reducing the query execution time and increasing the query completeness when exploring the web of linked data,
concretely it consists of creating an LTQP paradigm called CLTQP.
This paradigm enables query engines to collaborate in the exploration of data sources and the sharing of results through a P2P cache.
The potential of this proposal is to increase the completeness of query results and reducing the execution time of LTQP queries,
thus democratizing the creation and usage of large-scale social media applications.</p>

    </div>
</section>
 <!-- 0.5 -->
  <section>
<div datatype="rdf:HTML" property="schema:description">

      <p><strong>Supervisor</strong>:
<a href="https://pietercolpaert.be/">Pieter Colpaert</a>, <a href="https://www.rubensworks.net/">Ruben Taelman</a></p>

      <p><strong>Funding</strong>:
supported by SolidLab Vlaanderen (Flemish Government VV023/10) and the Research Foundation Flandes (FWO) under grant number S006323N</p>

    </div>
</section>
 
</main>

<footer><section>
<h2 id="references">References</h2>
<dl class="references">
  <dt id="ref-1">[1]</dt>
  <dd resource="#verstraete2022solid" typeof="schema:Article">Verstraete, M., Verbrugge, S., Colle, D.: Solid: Enabler of decentralized, digital platforms ecosystems. In: ITS (2022).</dd>
  <dt id="ref-2">[2]</dt>
  <dd resource="#Terranova2000FreeLP" typeof="schema:Article">Terranova, T.: Free Labor: Producing Culture for the Digital Economy. Social Text. (2000).</dd>
  <dt id="ref-3">[3]</dt>
  <dd resource="#Curran2016ch1" typeof="schema:Chapter">Curran, J.: The internet of dreams Reinterpreting the internet. In: Misunderstanding the Internet (2016).</dd>
  <dt id="ref-4">[4]</dt>
  <dd resource="https://doi.bak.org/10.1093/scipol/sct082" typeof="schema:Article">Sevignani, S.: The commodification of privacy on the Internet. Science and Public Policy. (2013).</dd>
  <dt id="ref-5">[5]</dt>
  <dd resource="#Smets2022SerendipityIR" typeof="schema:Article">Smets, A., Michiels, L., Bogers, T., Björneborn, L.: Serendipity in Recommender Systems Beyond the Algorithm: a Feature Repository and Experimental Design. In: IntRS@RecSys (2022).</dd>
  <dt id="ref-6">[6]</dt>
  <dd resource="#Hartig2016" typeof="schema:Article">Hartig, O., Özsu, M.T.: Walking Without a Map: Ranking-Based Traversal for Querying Linked Data. In: ISWC</dd>
  <dt id="ref-7">[7]</dt>
  <dd resource="#Hartig2014LinkedDQ" typeof="schema:Article">Hartig, O.: Linked Data Query Processing Based on Link Traversal. In: Linked Data Management</dd>
  <dt id="ref-8">[8]</dt>
  <dd resource="#hartig2012" typeof="schema:Article">Hartig, O., Freytag, J.-C.: Foundations of Traversal Based Query Execution over Linked Data. In: Conference on Hypertext and Social Media</dd>
  <dt id="ref-9">[9]</dt>
  <dd resource="#Grall2020" typeof="schema:Article">Grall, A., Skaf-Molli, H., Molli, P., Perrin, M.: Collaborative SPARQL Query Processing for Decentralized Semantic Data. In: Database and Expert Systems Applications. , Cham (2020).</dd>
  <dt id="ref-10">[10]</dt>
  <dd resource="https://hal-nantes-universite.archives-ouvertes.fr/hal-01805154" typeof="schema:Article">Grall, A., Skaf-Molli, H., Molli, P.: SPARQL Query Execution in Networks of Web Browsers. In: ISWC (2018).</dd>
  <dt id="ref-11">[11]</dt>
  <dd resource="https://doi.bak.org/10.1145/3442381.3450037" typeof="schema:Article">Aebeloe, C., Montoya, G., Hose, K.: ColChain: Collaborative Linked Data Networks. In: Proceedings of the Web Conference 2021 (2021).</dd>
  <dt id="ref-12">[12]</dt>
  <dd resource="#Shen2014AnIP" typeof="schema:Article">Shen, H., Lin, Y., Chandler, H.: An Interest-Based Per-Community P2P Hierarchical Structure for Short Video Sharing in the YouTube Social Network. IEEE. (2014).</dd>
  <dt id="ref-13">[13]</dt>
  <dd resource="#jin2006" typeof="schema:Article">Jin, H., Yu, Y.: SemreX: a Semantic Peer-to-Peer Scientific References Sharing System. In: AICT-ICIW’06 (2006).</dd>
  <dt id="ref-14">[14]</dt>
  <dd resource="#Iyer2002SquirrelAD" typeof="schema:Article">Iyer, S., Rowstron, A.I.T., Druschel, P.: Squirrel: a decentralized peer-to-peer web cache. In: ACM SIGACT-SIGOPS (2002).</dd>
  <dt id="ref-15">[15]</dt>
  <dd resource="#Manal2009" typeof="schema:Article">Dick, M.E., Pacitti, E., Kemme, B.: Flower-CDN: a hybrid P2P overlay for efficient query processing in CDN. In: International Conference on Extending Database Technology (2009).</dd>
  <dt id="ref-16">[16]</dt>
  <dd resource="#Frey2014" typeof="schema:Article">Frey, D., Goessens, M., Kermarrec, A.-M.: Behave: Behavioral Cache for Web Content. In: IFIP (2014).</dd>
  <dt id="ref-17">[17]</dt>
  <dd resource="#Folz2016" typeof="schema:Article">Folz, P., Skaf-Molli, H., Molli, P.: CyCLaDEs: A Decentralized Cache for Triple Pattern Fragments. In: The Semantic Web (2016).</dd>
  <dt id="ref-18">[18]</dt>
  <dd resource="#8029358" typeof="schema:Article">Feng, J., Meng, C., Song, J., Zhang, X., Feng, Z., Zou, L.: SPARQL Query Parallel Processing: A Survey. In: IEEE International Congress on Big Data (2017).</dd>
  <dt id="ref-19">[19]</dt>
  <dd resource="#Taelman2020" typeof="schema:Article">Taelman, R., Steyskal, S., Kirrane, S.: Towards Querying in Decentralized Environments with Privacy-Preserving Aggregation. ArXiv. (2020).</dd>
  <dt id="ref-20">[20]</dt>
  <dd resource="#taelman2023" typeof="schema:CreativeWork">Taelman, R., Verborgh, R.: Evaluation of Link Traversal Query Execution over Decentralized Environments with Structural Assumptions</dd>
  <dt id="ref-21">[21]</dt>
  <dd resource="#Hartig2011" typeof="schema:Article">Hartig, O.: How Caching Improves Efficiency and Result Completeness for Querying Linked Data. In: LDOW (2011).</dd>
  <dt id="ref-22">[22]</dt>
  <dd resource="https://doi.org/10.1145/2413176.2413215" typeof="schema:Article">Nilizadeh, S., Jahid, S., Mittal, P., Borisov, N., Kapadia, A.: Cachet: A Decentralized Architecture for Privacy Preserving Social Networking with Caching. In: Emerging Networking Experiments and Technologies (2012).</dd>
  <dt id="ref-23">[23]</dt>
  <dd resource="https://comunica.github.io/Article-ISWC2018-Resource/" typeof="schema:Article">Taelman, R., Van Herwegen, J., Vander Sande, M., Verborgh, R.: Comunica: a Modular SPARQL Query Engine for the Web. In: International Semantic Web Conference (2018).</dd>
</dl>
</section>
</footer>



</body>
</html>
